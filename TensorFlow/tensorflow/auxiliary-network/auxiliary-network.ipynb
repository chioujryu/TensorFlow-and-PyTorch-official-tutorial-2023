{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1099 - accuracy: 0.9658\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0392 - accuracy: 0.9878\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0263 - accuracy: 0.9917\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0176 - accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03915051743388176, 0.9911999702453613]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定義主分類器和輔助分類器\n",
    "def create_model(num_classes=10):\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"main\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 載入數據集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# 定義模型、損失函數和優化器\n",
    "model = create_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"main\": \"sparse_categorical_crossentropy\"},\n",
    "              loss_weights={\"main\": 1.0},\n",
    "              metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_images, {\"main\": train_labels}, epochs=10, batch_size=32)\n",
    "\n",
    "# 評估模型\n",
    "model.evaluate(test_images, {\"main\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1636 - main_loss: 0.1147 - aux_loss: 0.1223 - main_accuracy: 0.9646 - aux_accuracy: 0.9625\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0546 - main_loss: 0.0389 - aux_loss: 0.0393 - main_accuracy: 0.9882 - aux_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0362 - main_loss: 0.0258 - aux_loss: 0.0260 - main_accuracy: 0.9919 - aux_accuracy: 0.9917\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0260 - main_loss: 0.0185 - aux_loss: 0.0188 - main_accuracy: 0.9939 - aux_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0197 - main_loss: 0.0140 - aux_loss: 0.0142 - main_accuracy: 0.9955 - aux_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0149 - main_loss: 0.0106 - aux_loss: 0.0106 - main_accuracy: 0.9965 - aux_accuracy: 0.9965\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0117 - main_loss: 0.0083 - aux_loss: 0.0084 - main_accuracy: 0.9974 - aux_accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0114 - main_loss: 0.0081 - aux_loss: 0.0082 - main_accuracy: 0.9973 - aux_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0101 - main_loss: 0.0071 - aux_loss: 0.0074 - main_accuracy: 0.9977 - aux_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0067 - main_loss: 0.0047 - aux_loss: 0.0049 - main_accuracy: 0.9986 - aux_accuracy: 0.9986\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0568 - main_loss: 0.0409 - aux_loss: 0.0396 - main_accuracy: 0.9914 - aux_accuracy: 0.9911\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m model\u001b[39m.\u001b[39mfit(train_images, {\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m: train_labels, \u001b[39m\"\u001b[39m\u001b[39maux\u001b[39m\u001b[39m\"\u001b[39m: train_labels}, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[39m# 評估模型\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_images, {\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m: test_labels, \u001b[39m\"\u001b[39m\u001b[39maux\u001b[39m\u001b[39m\"\u001b[39m: test_labels})\n\u001b[0;32m     36\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest accuracy:\u001b[39m\u001b[39m\"\u001b[39m, test_acc)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定義主分類器和輔助分類器\n",
    "def create_model(num_classes=10):\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"main\")(x)\n",
    "    aux_outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"aux\")(x) # 輔助分類器\n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, aux_outputs])\n",
    "    return model\n",
    "\n",
    "# 載入數據集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# 定義模型、損失函數和優化器\n",
    "model = create_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss={\"main\": \"sparse_categorical_crossentropy\", \"aux\": \"sparse_categorical_crossentropy\"},\n",
    "              loss_weights={\"main\": 1.0, \"aux\": 0.4},\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_images, {\"main\": train_labels, \"aux\": train_labels}, epochs=10, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0568 - main_loss: 0.0409 - aux_loss: 0.0396 - main_accuracy: 0.9914 - aux_accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.056755680590867996,\n",
       " 0.04093068093061447,\n",
       " 0.03956262022256851,\n",
       " 0.9914000034332275,\n",
       " 0.991100013256073]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評估模型\n",
    "model.evaluate(test_images, {\"main\": test_labels, \"aux\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1696 - main_loss: 0.1075 - aux_loss: 0.1552 - main_accuracy: 0.9675 - aux_accuracy: 0.9531\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0593 - main_loss: 0.0372 - aux_loss: 0.0554 - main_accuracy: 0.9886 - aux_accuracy: 0.9850\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0390 - main_loss: 0.0237 - aux_loss: 0.0384 - main_accuracy: 0.9926 - aux_accuracy: 0.9893\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0298 - main_loss: 0.0175 - aux_loss: 0.0309 - main_accuracy: 0.9947 - aux_accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0209 - main_loss: 0.0122 - aux_loss: 0.0217 - main_accuracy: 0.9962 - aux_accuracy: 0.9942\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0179 - main_loss: 0.0098 - aux_loss: 0.0201 - main_accuracy: 0.9967 - aux_accuracy: 0.9949\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0136 - main_loss: 0.0076 - aux_loss: 0.0150 - main_accuracy: 0.9974 - aux_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0120 - main_loss: 0.0066 - aux_loss: 0.0134 - main_accuracy: 0.9979 - aux_accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0110 - main_loss: 0.0061 - aux_loss: 0.0122 - main_accuracy: 0.9980 - aux_accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0100 - main_loss: 0.0052 - aux_loss: 0.0118 - main_accuracy: 0.9984 - aux_accuracy: 0.9977\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0568 - main_loss: 0.0375 - aux_loss: 0.0484 - main_accuracy: 0.9916 - aux_accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.056799840182065964,\n",
       " 0.0374540314078331,\n",
       " 0.04836451634764671,\n",
       " 0.991599977016449,\n",
       " 0.991100013256073]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定義主分類器和輔助分類器\n",
    "def create_model(num_classes=10):\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"main\")(x)\n",
    "    \n",
    "    # 輔助分類器\n",
    "    aux = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    aux = keras.layers.Dense(128, activation=\"relu\")(aux)\n",
    "    aux = keras.layers.Dense(64, activation=\"relu\")(aux)\n",
    "    aux = keras.layers.Dense(32, activation=\"relu\")(aux)\n",
    "    aux_outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"aux\")(aux)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, aux_outputs])\n",
    "    return model\n",
    "\n",
    "# 載入數據集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# 定義模型、損失函數和優化器\n",
    "model = create_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"main\": \"sparse_categorical_crossentropy\", \"aux\": \"sparse_categorical_crossentropy\"},\n",
    "              loss_weights={\"main\": 1.0, \"aux\": 0.4},\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_images, {\"main\": train_labels, \"aux\": train_labels}, epochs=10, batch_size=32)\n",
    "\n",
    "# 評估模型\n",
    "model.evaluate(test_images, {\"main\": test_labels, \"aux\": test_labels})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果輔助層效果變好，主要網路的效果也會變好。反之亦然，如果輔助網路效果不好，主要網路效果也會不好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1503 - main_loss: 0.1106 - aux_loss: 0.0993 - main_accuracy: 0.9657 - aux_accuracy: 0.9694\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0514 - main_loss: 0.0376 - aux_loss: 0.0345 - main_accuracy: 0.9882 - aux_accuracy: 0.9893\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0339 - main_loss: 0.0254 - aux_loss: 0.0212 - main_accuracy: 0.9919 - aux_accuracy: 0.9934\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0231 - main_loss: 0.0174 - aux_loss: 0.0144 - main_accuracy: 0.9946 - aux_accuracy: 0.9954\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0185 - main_loss: 0.0144 - aux_loss: 0.0104 - main_accuracy: 0.9952 - aux_accuracy: 0.9966\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0139 - main_loss: 0.0105 - aux_loss: 0.0083 - main_accuracy: 0.9967 - aux_accuracy: 0.9973\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0116 - main_loss: 0.0087 - aux_loss: 0.0071 - main_accuracy: 0.9973 - aux_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0111 - main_loss: 0.0086 - aux_loss: 0.0064 - main_accuracy: 0.9972 - aux_accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0080 - main_loss: 0.0060 - aux_loss: 0.0051 - main_accuracy: 0.9981 - aux_accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0086 - main_loss: 0.0066 - aux_loss: 0.0050 - main_accuracy: 0.9978 - aux_accuracy: 0.9986\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0534 - main_loss: 0.0351 - aux_loss: 0.0456 - main_accuracy: 0.9918 - aux_accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.053360968828201294,\n",
       " 0.03513322025537491,\n",
       " 0.045569367706775665,\n",
       " 0.9918000102043152,\n",
       " 0.9904000163078308]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定義主分類器和輔助分類器\n",
    "def create_model(num_classes=10):\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"main\")(x)\n",
    "    \n",
    "\n",
    "    # 輔助分類器\n",
    "    aux = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    aux = keras.layers.MaxPooling2D(pool_size=(2, 2))(aux)\n",
    "    aux = keras.layers.Conv2D(64, 3, activation=\"relu\")(aux)\n",
    "    # aux = keras.layers.MaxPooling2D(pool_size=(2, 2))(aux)\n",
    "    # aux = keras.layers.Conv2D(128,3, activation=\"relu\")(aux)\n",
    "    aux = keras.layers.Flatten()(aux)\n",
    "    aux = keras.layers.Dense(512, activation=\"relu\")(aux)\n",
    "    aux_outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"aux\")(aux)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, aux_outputs])\n",
    "    return model\n",
    "\n",
    "# 載入數據集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# 定義模型、損失函數和優化器\n",
    "model = create_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"main\": \"sparse_categorical_crossentropy\", \"aux\": \"sparse_categorical_crossentropy\"},\n",
    "              loss_weights={\"main\": 1.0, \"aux\": 0.4},\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_images, {\"main\": train_labels, \"aux\": train_labels}, epochs=10, batch_size=32)\n",
    "\n",
    "# 評估模型\n",
    "model.evaluate(test_images, {\"main\": test_labels, \"aux\": test_labels})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 26, 26, 32), dtype=tf.float32, name=None), name='conv2d_130/Relu:0', description=\"created by layer 'conv2d_130'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 32), dtype=tf.float32, name=None), name='max_pooling2d_105/MaxPool:0', description=\"created by layer 'max_pooling2d_105'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 32), dtype=tf.float32, name=None), name='max_pooling2d_105/MaxPool:0', description=\"created by layer 'max_pooling2d_105'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 5, 64), dtype=tf.float32, name=None), name='max_pooling2d_106/MaxPool:0', description=\"created by layer 'max_pooling2d_106'\")\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1621 - main_loss: 0.1106 - aux_loss: 0.1286 - main_accuracy: 0.9663 - aux_accuracy: 0.9596\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0557 - main_loss: 0.0377 - aux_loss: 0.0451 - main_accuracy: 0.9883 - aux_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0373 - main_loss: 0.0243 - aux_loss: 0.0327 - main_accuracy: 0.9924 - aux_accuracy: 0.9907\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0271 - main_loss: 0.0174 - aux_loss: 0.0245 - main_accuracy: 0.9943 - aux_accuracy: 0.9929\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0196 - main_loss: 0.0116 - aux_loss: 0.0202 - main_accuracy: 0.9964 - aux_accuracy: 0.9941\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0168 - main_loss: 0.0101 - aux_loss: 0.0167 - main_accuracy: 0.9967 - aux_accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0142 - main_loss: 0.0085 - aux_loss: 0.0145 - main_accuracy: 0.9973 - aux_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0109 - main_loss: 0.0061 - aux_loss: 0.0121 - main_accuracy: 0.9980 - aux_accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0104 - main_loss: 0.0057 - aux_loss: 0.0118 - main_accuracy: 0.9980 - aux_accuracy: 0.9968\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0084 - main_loss: 0.0048 - aux_loss: 0.0092 - main_accuracy: 0.9986 - aux_accuracy: 0.9975\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0497 - main_loss: 0.0315 - aux_loss: 0.0455 - main_accuracy: 0.9925 - aux_accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04968259111046791,\n",
       " 0.03149300068616867,\n",
       " 0.045473963022232056,\n",
       " 0.9925000071525574,\n",
       " 0.9918000102043152]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定義主分類器和輔助分類器\n",
    "def create_model(num_classes=10):\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    print(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    print(x)\n",
    "    x_1 = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    print(x)\n",
    "    x_2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(x_1)\n",
    "    print(x_2)\n",
    "    x_3 = keras.layers.Flatten()(x_2)\n",
    "    x_3 = keras.layers.Dense(512, activation=\"relu\")(x_3)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"main\")(x_3)\n",
    "    \n",
    "\n",
    "    # 輔助分類器\n",
    "    aux = keras.layers.Conv2D(128, 3, activation=\"relu\")(x_2)\n",
    "    # aux = keras.layers.Conv2D(256, 3, activation=\"relu\")(aux)\n",
    "    aux = keras.layers.Flatten()(aux)\n",
    "    aux = keras.layers.Dense(512, activation=\"relu\")(aux)\n",
    "    aux_outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"aux\")(aux)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, aux_outputs])\n",
    "    return model\n",
    "\n",
    "# 載入數據集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# 定義模型、損失函數和優化器\n",
    "model = create_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"main\": \"sparse_categorical_crossentropy\", \"aux\": \"sparse_categorical_crossentropy\"},\n",
    "              loss_weights={\"main\": 1.0, \"aux\": 0.4},\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_images, {\"main\": train_labels, \"aux\": train_labels}, epochs=10, batch_size=32)\n",
    "\n",
    "# 評估模型\n",
    "model.evaluate(test_images, {\"main\": test_labels, \"aux\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 26, 26, 32), dtype=tf.float32, name=None), name='conv2d_149/Relu:0', description=\"created by layer 'conv2d_149'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 32), dtype=tf.float32, name=None), name='max_pooling2d_115/MaxPool:0', description=\"created by layer 'max_pooling2d_115'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 32), dtype=tf.float32, name=None), name='max_pooling2d_115/MaxPool:0', description=\"created by layer 'max_pooling2d_115'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 5, 64), dtype=tf.float32, name=None), name='max_pooling2d_116/MaxPool:0', description=\"created by layer 'max_pooling2d_116'\")\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 21s 10ms/step - loss: 0.1547 - main_loss: 0.1127 - aux_loss: 0.1050 - main_accuracy: 0.9654 - aux_accuracy: 0.9679\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0536 - main_loss: 0.0383 - aux_loss: 0.0383 - main_accuracy: 0.9880 - aux_accuracy: 0.9889\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0354 - main_loss: 0.0245 - aux_loss: 0.0273 - main_accuracy: 0.9924 - aux_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0248 - main_loss: 0.0171 - aux_loss: 0.0194 - main_accuracy: 0.9944 - aux_accuracy: 0.9938\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0200 - main_loss: 0.0130 - aux_loss: 0.0177 - main_accuracy: 0.9954 - aux_accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0151 - main_loss: 0.0099 - aux_loss: 0.0131 - main_accuracy: 0.9970 - aux_accuracy: 0.9961\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0126 - main_loss: 0.0078 - aux_loss: 0.0120 - main_accuracy: 0.9974 - aux_accuracy: 0.9963\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0113 - main_loss: 0.0073 - aux_loss: 0.0100 - main_accuracy: 0.9974 - aux_accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0082 - main_loss: 0.0050 - aux_loss: 0.0080 - main_accuracy: 0.9985 - aux_accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0099 - main_loss: 0.0056 - aux_loss: 0.0108 - main_accuracy: 0.9980 - aux_accuracy: 0.9974\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0510 - main_loss: 0.0351 - aux_loss: 0.0397 - main_accuracy: 0.9922 - aux_accuracy: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05099499970674515,\n",
       " 0.03509683907032013,\n",
       " 0.03974537178874016,\n",
       " 0.9922000169754028,\n",
       " 0.9922999739646912]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定義主分類器和輔助分類器\n",
    "def create_model(num_classes=10):\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    print(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    print(x)\n",
    "    x_1 = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    print(x)\n",
    "    x_2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(x_1)\n",
    "    print(x_2)\n",
    "    x_3 = keras.layers.Flatten()(x_2)\n",
    "    x_3 = keras.layers.Dense(512, activation=\"relu\")(x_3)\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"main\")(x_3)\n",
    "    \n",
    "\n",
    "    # 輔助分類器\n",
    "    aux = keras.layers.Conv2D(512, 3, activation=\"relu\")(x_1)\n",
    "    aux = keras.layers.Conv2D(256, 3, activation=\"relu\")(aux)\n",
    "    # aux = keras.layers.Conv2D(512, 3, activation=\"relu\")(aux)\n",
    "    aux = keras.layers.Flatten()(aux)\n",
    "    aux = keras.layers.Dense(128, activation=\"relu\")(aux)\n",
    "    aux_outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"aux\")(aux)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, aux_outputs])\n",
    "    return model\n",
    "\n",
    "# 載入數據集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)) / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)) / 255.0\n",
    "\n",
    "# 定義模型、損失函數和優化器\n",
    "model = create_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"main\": \"sparse_categorical_crossentropy\", \"aux\": \"sparse_categorical_crossentropy\"},\n",
    "              loss_weights={\"main\": 1.0, \"aux\": 0.4},\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_images, {\"main\": train_labels, \"aux\": train_labels}, epochs=10, batch_size=32)\n",
    "\n",
    "# 評估模型\n",
    "model.evaluate(test_images, {\"main\": test_labels, \"aux\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.7458148e-16, 1.1920670e-13, 1.7102119e-15, ..., 1.0000000e+00,\n",
       "         4.4441987e-16, 6.4844585e-10],\n",
       "        [1.9304737e-13, 4.7757839e-12, 1.0000000e+00, ..., 1.6772533e-17,\n",
       "         5.5223024e-20, 2.2093446e-19],\n",
       "        [3.5799003e-12, 1.0000000e+00, 2.6357840e-12, ..., 5.1620206e-09,\n",
       "         7.8109863e-10, 3.8822813e-14],\n",
       "        ...,\n",
       "        [1.2129932e-25, 2.5958121e-15, 5.9755734e-18, ..., 1.6096574e-14,\n",
       "         2.2956273e-13, 4.8276982e-18],\n",
       "        [2.8622013e-13, 7.4713871e-17, 2.2243975e-19, ..., 1.8704598e-19,\n",
       "         3.7252987e-12, 1.8214688e-16],\n",
       "        [5.7477099e-09, 1.1588158e-10, 7.3195150e-10, ..., 3.4450324e-14,\n",
       "         2.3217974e-09, 9.0989466e-11]], dtype=float32),\n",
       " array([[7.59857724e-24, 1.83766380e-20, 4.83106720e-19, ...,\n",
       "         1.00000000e+00, 1.78132504e-24, 3.57897811e-16],\n",
       "        [7.41591844e-28, 9.25544973e-14, 1.00000000e+00, ...,\n",
       "         3.00417833e-19, 1.14065274e-20, 1.64507877e-21],\n",
       "        [1.62776259e-13, 9.99999881e-01, 1.80284837e-13, ...,\n",
       "         1.15970011e-10, 9.49238412e-08, 3.75836894e-13],\n",
       "        ...,\n",
       "        [8.39537034e-25, 6.19381450e-15, 1.77595587e-19, ...,\n",
       "         9.49228300e-18, 1.47102751e-12, 6.70484068e-12],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 7.61956252e-24, 5.41305289e-28],\n",
       "        [1.01605648e-25, 2.49955431e-27, 5.80280990e-16, ...,\n",
       "         9.03638431e-31, 1.91145157e-27, 4.47418902e-23]], dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "probs = model.predict(test_images)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7, 2, 1, ..., 4, 5, 6], dtype=int64),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=int64)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for prob in probs:\n",
    "    preds.append(prob.argmax(axis=1))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_2.8.3__python_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
