{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning for on-device inference w/ XNNPACK\n",
    "\n",
    "Welcome to the guide on Keras weights pruning for improving latency of on-device inference via [XNNPACK](https://github.com/google/XNNPACK).\n",
    "\n",
    "欢迎阅读Keras权重修剪指南，以通过XNNPACK改善设备上推理的延迟。\n",
    "\n",
    "<br>\n",
    "\n",
    "This guide presents the usage of the newly introduced `tfmot.sparsity.keras.PruningPolicy` API and demonstrates how it could be used for accelerating mostly convolutional models on modern CPUs using [XNNPACK Sparse inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#sparse-inference).\n",
    "\n",
    "本指南介绍了新引入的API的用法 `tfmot.sparsity.keras.PruningPolicy` ，并演示了如何使用XNNPACK稀疏推理在现代CPU上加速主要的卷积模型。\n",
    "\n",
    "<br>\n",
    "\n",
    "The guide covers the following steps of the model creation process:\n",
    "\n",
    "本指南涵盖了模型创建过程的以下步骤：\n",
    "\n",
    "* Build and train the dense baseline 构建并训练密集基线\n",
    "* Fine-tune model with pruning 使用修剪微调模型\n",
    "* Convert to TFLite 转换为TFLite\n",
    "* On-device benchmark 设备上基准测试\n",
    "\n",
    "<br>\n",
    "\n",
    "The guide doesn't cover the best practices for the fine-tuning with pruning. For more detailed information on this topic, please check out our [comprehensive guide](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md).\n",
    "\n",
    "本指南没有介绍使用修剪进行微调的最佳实践。有关此主题的更多详细信息，请查看我们的[综合指南](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md)。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q tensorflow\n",
    "# pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the dense model 构建和训练密集模型\n",
    "\n",
    "We build and train a simple baseline CNN for classification task on [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n",
    "\n",
    "我们构建并训练了一个简单的基线CNN，用于[CIFAR10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)的分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 dataset.\n",
    "\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\"cifar10\",\n",
    "                                        split=['train[:90%]', 'train[90%:]', 'test'],\n",
    "                                        as_supervised=True,\n",
    "                                        with_info=True,\n",
    "                                        )\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "def normalize_img(img, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.image.convert_image_dtype(img, tf.float32), label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in batches of 128 images.\n",
    "\n",
    "batch_size = 128\n",
    "def prepare_dataset(ds, buffer_size=None):\n",
    "    ds = ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE) # 将ds数据集中的每个元素传递给normalize_img函数进行预处理。\n",
    "    ds = ds.cache() # cache方法将预处理后的数据集缓存到内存中，可以在需要多次迭代访问数据集时提高访问速度。\n",
    "    if buffer_size:\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "    ds = ds.batch(batch_size) # ds.batch(batch_size)表示将ds数据集划分为多个批次，每个批次包含batch_size个元素。\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE) # 当模型训练时，prefetch方法会异步地从数据集中预取一定数量的元素，并将它们放入缓冲区中。\n",
    "    return ds\n",
    "\n",
    "ds_train = prepare_dataset(ds_train, ds_info.splits['train'].num_examples)\n",
    "ds_val = prepare_dataset(ds_val)\n",
    "ds_test = prepare_dataset(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dense baseline model.\n",
    "\n",
    "dense_model = keras.Sequential([keras.layers.InputLayer(input_shape=(32,32,3)),\n",
    "\n",
    "                                keras.layers.ZeroPadding2D(padding=1), # 使用ZeroPadding2D层，我们可以有效地扩展输入特征图的大小，而不会损失输入图像的信息。\n",
    "\n",
    "                                keras.layers.Conv2D(filters=8,kernel_size=(3, 3),strides=(2, 2),padding='valid'),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.ReLU(),\n",
    "\n",
    "                                keras.layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same'),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.ReLU(),\n",
    "\n",
    "                                keras.layers.Conv2D(filters=16, kernel_size=(1, 1)),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.ReLU(),\n",
    "\n",
    "                                keras.layers.ZeroPadding2D(padding=1),\n",
    "\n",
    "                                keras.layers.DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='valid'),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.ReLU(),\n",
    "\n",
    "                                keras.layers.Conv2D(filters=32, kernel_size=(1, 1)),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.ReLU(),\n",
    "\n",
    "                                keras.layers.GlobalAveragePooling2D(),\n",
    "                                keras.layers.Flatten(),\n",
    "                                keras.layers.Dense(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the dense model for 10 epochs.\n",
    "dense_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 2s - loss: 1.4151 - accuracy: 0.4879 - val_loss: 1.4340 - val_accuracy: 0.4856 - 2s/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "352/352 - 3s - loss: 1.4071 - accuracy: 0.4920 - val_loss: 1.5042 - val_accuracy: 0.4682 - 3s/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "352/352 - 2s - loss: 1.3999 - accuracy: 0.4938 - val_loss: 1.4051 - val_accuracy: 0.4970 - 2s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "352/352 - 3s - loss: 1.3931 - accuracy: 0.4970 - val_loss: 1.4201 - val_accuracy: 0.4706 - 3s/epoch - 8ms/step\n",
      "Epoch 5/10\n",
      "352/352 - 2s - loss: 1.3864 - accuracy: 0.5008 - val_loss: 1.3930 - val_accuracy: 0.4928 - 2s/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "352/352 - 3s - loss: 1.3771 - accuracy: 0.5041 - val_loss: 1.4876 - val_accuracy: 0.4630 - 3s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "352/352 - 2s - loss: 1.3739 - accuracy: 0.5050 - val_loss: 1.4081 - val_accuracy: 0.4882 - 2s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "352/352 - 3s - loss: 1.3681 - accuracy: 0.5085 - val_loss: 1.4423 - val_accuracy: 0.4754 - 3s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "352/352 - 1s - loss: 1.3612 - accuracy: 0.5110 - val_loss: 1.4013 - val_accuracy: 0.4942 - 1s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "352/352 - 2s - loss: 1.3565 - accuracy: 0.5131 - val_loss: 1.4608 - val_accuracy: 0.4778 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc0883cabb0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.fit(\n",
    "  ds_train,\n",
    "  epochs=10,\n",
    "  validation_data=ds_val,\n",
    "  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/79 [===========>..................] - ETA: 0s - loss: 1.4429 - accuracy: 0.4761"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 1.4520 - accuracy: 0.4724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4520046710968018, 0.4724000096321106]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the dense model\n",
    "dense_model.evaluate(ds_test, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the sparse model 构建稀疏模型\n",
    "\n",
    "Using the instructions from the [comprehensive guide](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md), we apply `tfmot.sparsity.keras.prune_low_magnitude` function with parameters that target on-device acceleration via pruning i.e. `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` policy.\n",
    "\n",
    "使用来自[综合指南](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md)的说明，我们应用 `tfmot.sparsity.keras.prune_low_magnitude` 具有通过修剪以设备上加速为目标的参数的函数，即政策 `tfmot.sparsity.keras.PruneForLatencyOnXNNPack` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after after 5 epochs.\n",
    "end_epochs = 5\n",
    "\n",
    "num_iterations_per_epoch = len(ds_train)  # 幾個 batch\n",
    "end_step  = num_iterations_per_epoch  * end_epochs\n",
    "\n",
    "# Define parameters for pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow_2.8.3__Python_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
